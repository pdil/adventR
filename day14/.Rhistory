school's cheerleading squad.
UNM Traditions - Cherry and Silver
The most common origin of New Mexico's school colors dates back nearly 100
years. Apparently, the school colors in the early 1890s were black and gold.
Ms. Harriet Jenness, a faculty member who taught drawing, delsarte (drama),
penmanship and music, suggested a change in school colors because black and
gold did not give a true feeling of New Mexico. She suggested the crimson
evening glow of the majestic Sandia mountains to the east. The silver came from
when students and faculty took picnics in the Sandias and noted the Rio Grande
looked like a silver ribbon winding through the valley below. Her ideas were
enthusiastically adopted by the faculty and staff. The crimson was later
changed to cherry, the color of a Sandia sunset. Miss Jenness died in 1895, two
years before the colors were adopted as official. From 1973-79, turquoise was
integrated into the official school colors, at least, for the athletics teams.
The football team wore turquoise jerseys at home during those years. Cherry and
silver returned as the predominant colors in 1980.
UNM Traditions - The Alma Mater
The Alma Mater (in Latin means Nourishing or Dear Mother) was a source of
contention at UNM in 1947. The original Alma Mater was set to the tune of
Annie Lyle, which was an unpopular tune with the student body for a long
period of time. The student body voted in a general election to change the Alma
Mater and found Glee Club Director Craig Summers to oblige. Actually Mr.
Summers and his father wrote the present Alma Mater three years before and
called it The New Mexico Hymn.
New Mexico, New Mexico
We sing to honor thee.
This golden haze of college days
Will live in memory.
This praise we sing will ever ring
With truth and loyalty New Mexico, your fame we know
Will last eternally.
UNM Traditions - The Fight Song
The UNM fight Song was written in 1930. The music to the Fight Song was written
by Dean Lena Clauve, who served the University for 32 years as a professor of
music education and as the Dean of Women. Dr. George St. Clair, professor in
the English Department, wrote the lyrics.
Hail to thee, New Mexico,
Thy loyal sons are we. Marching down the field we go,
Fighting for thee.
RAH! RAH! RAH!
Now we pledge our faith to thee,
Never shall we fail.
Fighting ever, yielding never.
HAIL! HAIL! HAIL!
")
wordcloud(unm.about, colors = brewer.pal(6,"Dark2"), random.order = FALSE)
43.279918+2.435302
43.279918+11.483362
53.0538+1.7556
53.0538+7.6372
53.0538-3.6598
49.394+1.7556
49.394+7.6372
iris
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill=~Species) %>% layer_points()
install.packages("%>%")
install.packages("magrittr")
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill=~Species) %>% layer_points()
library(ggvis)
library(magrittr)
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill=~Species) %>% layer_points()
install.packages("ggvis")
library(ggvis)
library(magrittr)
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill=~Species) %>% layer_points()
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill=~Species) %>% layer_points()
head(iris)
str(iris)
table(iris$Species)
table(iris$Sepal.Length)
round(prop.table(table(iris$Species)) * 100, digits=1)
summary(iris)
summary(iris[c["Sepal.Width", "Petal.Width"]])
summary(iris[c("Sepal.Width", "Petal.Width")])
install.packages("class")
library(class)
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
summary(iris)
summary(iris_norm)
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
head(ind)
ind
iris.training <- iris[ind==1, 1:4]
iris.test <- iris[ind==2, 1:4]
iris.trainLabels <- iris[ind==1, 5]
iris.testLabels <- iris[ind==2, 5]
iris_pred <- knn(train=iris.training, test=iris.test, cl=iris.trainLabels, k=3)
iris_pred
c(iris.testLabels, iris_pred)
cbind(iris.testLabels, iris_pred)
iris.testLabels
rbind(iris.testLabels, iris_pred)
as.matrix(cbind(iris.testLabels, test_pred))
as.matrix(cbind(iris.testLabels, iris_pred))
as.character(cbind(iris.testLabels, iris_pred))
install.packages(gmodels)
install.packages("gmodels")
library(gmodels)
CrossTable(x=iris.testLabels, y=iris_pred, prop.chisq=FALSE)
source('~/Desktop/knn.R')
cat('point 1 mem', memory.size(), memory.size(max=TRUE), '\n')
a <- 1:100
object.size(a)
b <- 1:1000
object.size(b)
df <- as.dataframe(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
head(df)
df <- as.dataframe(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df[[i,1]] <- i
df[[i,2]] <- object.size(q)
}
head(df)
df <- as.dataframe(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df$n[i] <- i
df$size[i] <- object.size(q)
}
head(df)
df <- data.frame(n=numeric(0), size=numeric(0))
for(i in 1:1000) {
q <- 1:i
df <- rbind(df, data.frame(n=i, size=object.size(q)))
}
head(df)
df <- data.frame(n=numeric(0), size=numeric(0))
for(i in 1:1000) {
q <- 1:i
df <- rbind(df, data.frame(n=i, size=object.size(q)))
}
df
df <- data.frame(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
df
df <- data.frame(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
library(ggplot2)
p <- ggplot(data=df, aes(x=i, y=size)) + geom_point()
print(p)
df <- data.frame(n=numeric(1000), size=numeric(1000))
for(i in 1:1000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
library(ggplot2)
p <- ggplot(data=df, aes(x=n, y=size)) + geom_point()
print(p)
df <- data.frame(n=numeric(10000), size=numeric(10000))
for(i in 1:10000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
library(ggplot2)
p <- ggplot(data=df, aes(x=n, y=size)) + geom_point()
print(p)
df <- data.frame(n=numeric(10000), size=numeric(10000))
for(i in 1:10000) {
q <- 1:i
df[i,1] <- i
df[i,2] <- object.size(q)
}
library(ggplot2)
p <- ggplot(data=df, aes(x=n, y=size)) + geom_point() + xlab("Number of list elements") + ylab("Size of list (bytes)")
print(p)
install.packages(tikzDevice)
install.packages("tikzDevice")
v <- factor(c("2", "3", "5", "7", "11"))
str(v)
library(lubridate)
?strsplit
?matrix
unlist(mess.data)
?vapply
?regex
?gsub
install.packages("ISLR")
library(ISLR)
data(College)
str(College)
fix(College)
view(College)
View(College)
rownames(College) = College[, 1]
summary(College)
pairs(College[, 1:10])
pairs
?pairs
pairs(College[, 1:10])
attach(College)
plot(Outstate, Private)
plot(Private, Outstate)
plot(College$Private, College$Outstate)
Elite <- rep("No", nrow(College))
Elite[which(College$Top10perc > 50)] <- "Yes"
Elite <- as.factor(Elite)
College <- data.frame(College, Elite)
summary(College)
plot(College$Elite, College$Outstate)
par(mfrow=c(2, 2))
hist(College$Room.Board, bins=10)
par(mfrow=c(2, 2))
par(mfrow=c(2, 2))
hist(College$Room.Board, binwidth=10)
par(mfrow=c(2, 2))
par(mfrow=c(2, 2))
hist(College$Room.Board, breaks=10)
hist(College$Books, breaks=10)
hist(College$Room.Board, breaks=10)
hist(College$Books, breaks=100)
par(mfrow=c(2, 2))
hist(College$Room.Board, breaks=10)
hist(College$Books, breaks=20)
hist(College$Grad.Rate, breaks=20)
hist(College$Phd, breaks=20)
hist(College$Top10perc, breaks=20)
data(Auto)
str(Auto)
range(Auto)
range(Auto[, 1:8])
range(Auto$year, Auto$origin)
range(Auto$mpg)
lapply(Auto[, 1:8], range)
sapply(Auto[, 1:8], range)
sapply(Auto[, 1:8], mean)
sapply(Auto[, 1:8], sd)
newAuto <- Auto[-10:85, 1:8]
newAuto <- Auto[-c(10:85), 1:8]
sapply(newAuto, mean)
sapply(Auto, range)
sapply(Auto, mean)
newAuto <- Auto[-c(10:85), ]
sapply(newAuto[, 1:8], mean)
sapply(newAuto[, 1:8], sd)
sapply(Auto[, 1:8], mean)
sapply(Auto[, 1:8], sd)
sapply(newAuto[, 1:8], mean)
sapply(newAuto[, 1:8], sd)
sapply(newAuto[, 1:8], range)
sapply(Auto[, 1:8], range)
plot(Auto$cylinders, Auto$displacement)
?par
par(new=TRUE)
plot(Auto$cylinders, Auto$displacement)
par
par()
par(mfrow=c(1, 1))
plot(Auto$cylinders, Auto$displacement)
plot(Auto$weight, Auto$mpg)
plot(Auto$year, Auto$horsepower)
par(mforw=c(2, 2))
par(mfrow=c(2, 2))
plot(Auto$cylinders, Auto$mpg)
plot(Auto$weight, Auto$mpg)
plot(Auto$year, Auto$mpg)
plot(Auto$displacement, Auto$mpg)
ar(mfrow=c(2, 3))
plot(Auto$cylinders, Auto$mpg)
plot(Auto$weight, Auto$mpg)
plot(Auto$year, Auto$mpg)
plot(Auto$displacement, Auto$mpg)
plot(Auto$acceleration, Auto$mpg)
plot(Auto$horsepower, Auto$mpg)
par(mfrow=c(2, 3))
plot(Auto$cylinders, Auto$mpg)
plot(Auto$weight, Auto$mpg)
plot(Auto$year, Auto$mpg)
plot(Auto$displacement, Auto$mpg)
plot(Auto$acceleration, Auto$mpg)
plot(Auto$horsepower, Auto$mpg)
plot(Auto$cylinders, Auto$displacement)
data(Boston)
library(MASS)
data(Boston)
?Boston
pairs(Boston)
pairs(Boston[, 1:5])
?Boston
sapply(Boston[, c("crim", "tax", "ptratio")], range)
length(which(Boston$chas == 1))
median(Boston$ptratio)
str(Boston)
Boston[which(Boston$medv == min(Boston$medv)), ]
length(which(Boston$rm > 7))
length(which(Boston$rm > 8))
Boston[which(Boston$rm > 8), ]
install.packages(c("rJava", "Rcpp", "RJSONIO", "bitops", "digest",
"functional", "stringr", "plyr", "reshape2", "dplyr",
"R.methodsS3", "caTools", "Hmisc"))
library(choroplethr)
example("choroplethr")
example("admin1_choropleth")
?admin1_choropleth
data(df_japan_census)
head(df_japan_census)
# set the value we want to map to be the 2010 population estimates
df_japan_census$value=df_japan_census$pop_2010
# default map of all of japan
admin1_choropleth("japan",
df_japan_census,
"2010 Japan Population Estimates",
"Population")
# zoom in on the Kansai region and use a continuous scale
kansai = c("mie", "nara", "wakayama", "kyoto", "osaka", "hyogo", "shiga")
admin1_choropleth("japan",
df_japan_census,
"2010 Japan Population Estimates",
"Population",
1,
kansai)
install.packages("choroplethrAdmin1")
data(df_japan_census)
head(df_japan_census)
# set the value we want to map to be the 2010 population estimates
df_japan_census$value=df_japan_census$pop_2010
# default map of all of japan
admin1_choropleth("japan",
df_japan_census,
"2010 Japan Population Estimates",
"Population")
# zoom in on the Kansai region and use a continuous scale
kansai = c("mie", "nara", "wakayama", "kyoto", "osaka", "hyogo", "shiga")
admin1_choropleth("japan",
df_japan_census,
"2010 Japan Population Estimates",
"Population",
1,
kansai)
?choropleth
?choroplethr
x <- runif(7, 0, 15)
x
x <- as.integer(runif(7, 0, 15))
x
barplot(x)
x <- as.integer(runif(70, 0, 15))
x
barplot(x)
x <- rnorm(100, 3, 2)
barplot(x)
hist(x)
plot(density(x))
plot(density(x), col = "red")
plot(density(x), col = "red", fill = "blue")
boxplot(x)
vioplot(x)
vioplot::vioplot(x)
library(vioplot)
vioplot(x)
library(vioplot, xmax = 10)
library(vioplot, xlim = c(0, 10))
install.packages("noncensus")
install.packages("zipcode")
library(dplyr)
library(zipcode)
data(zipcode)
View(zipcode)
zipcode %>% filter(city == "Newark", state == "NJ") %>% select(zip)
filter(zipcode, city == "Newark", state == "NJ")
select(filter(zipcode, city == "Newark", state == "NJ"), "zip")
select(filter(zipcode, city == "Newark", state == "NJ"), zip)
zipcode %>% filter(city == "West Caldwell", state == "NJ") %>% select(zip)
zipcode %>% filter(city == "Caldwell", state == "NJ") %>% select(zip)
zipcode %>% filter(city == "Wharton", state == "NJ") %>% select(zip)
zipcode %>% filter(city == "West Palm Beach", state == "FL") %>% select(zip)
library(readr)
input <- read_file("http://adventofcode.com/day/1/input")
input
input <- read_file("http://adventofcode.com/day/1/input.txt")
input <- read_file("/Users/paolo/Desktop/input.txt")
input
input_edit <- gsub("(", "", input)
input_edit <- gsub("'('", "", input)
input_edit <- gsub("\(", "", input)
input_edit <- gsub("/(", "", input)
input_edit <- gsub('\(', "", input)
input_edit <- gsub("[(]", "", input)
num_up <- nchar(input) - nchar(input_edit)
num_down <- nchar(input) - num_up
num_up - num_down
setwd("~/Desktop/github/adventR/day14")
library(readr)
input <- read_lines("input.txt")
input
lines <- strsplit(input, "")
lines
lines <- strsplit(input, " ")
lines
library(plyr)
parse_lines <- function(line) {
speed <- line[4]
runtime <- line[7]
resttime <- line[14]
data.frame(speed = speed, runtime = runtime, resttime = resttime)
}
df <- ldply(lines, parse_lines)
df
library(dplyr)
df
end <- 2503
df %>% mutate(distance = floor(end / (speed * runtime + resttime)) + (end %% (speed * runtime + resstime)))
df %>% mutate(distance = floor(end / (speed * runtime + resttime)) + (end %% (speed * runtime + restime)))
str(df)
parse_lines <- function(line) {
speed <- as.numeric(line[4])
runtime <- as.numeric(line[7])
resttime <- as.numeric(line[14])
data.frame(speed = speed, runtime = runtime, resttime = resttime)
}
df <- ldply(lines, parse_lines)
end <- 2503
df %>% mutate(distance = floor(end / (speed * runtime + resttime)) + (end %% (speed * runtime + restime)))
df %>% mutate(distance = floor(end / (speed * runtime + resttime)) + (end %% (speed * runtime + resttime)))
df %>% mutate(avg_speed = speed * runtime / (runtime + resttime))
df %>% mutate(avg_speed = speed * runtime / (runtime + resttime)) %>%
mutate(avg_speed * end)
df %>% mutate(distance = end / (speed * runtime + resttime))
df %>% mutate(distance = end / (runtime + resttime) * speed)
df %>% mutate(distance = (floor(end / (runtime + resttime)) + (end %% (runtime + resttime))) * speed)
df %>% mutate(distance = speed * runtime * end / (runtime + resttime) + speed * min(runtime, end % (runtime + resttime)))
df %>% mutate(distance = speed * runtime * end / (runtime + resttime) + speed * min(runtime, end %% (runtime + resttime)))
df %>% mutate(distance = speed * runtime * floor(end / (runtime + resttime)) + speed * min(runtime, end %% (runtime + resttime)))
df %>% mutate(distance = speed * runtime * floor(end / (runtime + resttime)) + speed * min(runtime, end %% (runtime + resttime))) %>%
select(distance) %>% max
parse_lines <- function(line) {
data.frame(
name = as.numeric(line[1]),
speed = as.numeric(line[4]),
runtime = as.numeric(line[7]),
resttime = as.numeric(line[14])
)
}
df <- read_lines("input.txt") %>% strsplit(" ") %>% ldply(parse_lines)
# distances after 2503 seconds
end <- 2503
df %>%
mutate(distance = speed * runtime * floor(end / (runtime + resttime)) +
speed * min(runtime, end %% (runtime + resttime))) %>%
select(distance) %>% max
parse_lines <- function(line) {
data.frame(
name = line[1],
speed = as.numeric(line[4]),
runtime = as.numeric(line[7]),
resttime = as.numeric(line[14])
)
}
df <- read_lines("input.txt") %>% strsplit(" ") %>% ldply(parse_lines)
# distances after 2503 seconds
end <- 2503
df %>%
mutate(distance = speed * runtime * floor(end / (runtime + resttime)) +
speed * min(runtime, end %% (runtime + resttime)))
df %>%
mutate(distance = speed * runtime * floor(end / (runtime + resttime)) +
speed * min(runtime, end %% (runtime + resttime))) %>%
filter(distance == max(distance))
df %>%
mutate(distance = speed * runtime * floor(end / (runtime + resttime)) +
speed * pmin(runtime, end %% (runtime + resttime))) %>%
filter(distance == max(distance))
View(df_japan_census)
?foreach
?for
foreach
foreach(i in c(1, 2, 3))
library(readr)
library(plyr)
library(dplyr)
parse_lines <- function(line) {
data.frame(
name = line[1],
speed = as.numeric(line[4]),
runtime = as.numeric(line[7]),
resttime = as.numeric(line[14])
)
}
df <- read_lines("input.txt") %>% strsplit(" ") %>% ldply(parse_lines)
# distances after 2503 seconds
end <- 2503
iterate_second <- function(t) {
df %>% mutate(distance = speed * runtime * floor(t / (runtime + resttime)) +
speed * pmin(runtime, t %% (runtime + resttime)))
}
1:end %>% ldply(interate_second) %>% filter(time == end)
1:end %>% ldply(iterate_second) %>% filter(time == end)
1:end %>% ldply(iterate_second)
result <- 1:end %>% ldply(iterate_second)
tail(result, 8)
